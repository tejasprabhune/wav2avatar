{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wav2avatar.streaming.hifigan.hifigan_discriminators' from '/home/prabhune/wav2avatar/wav2avatar/streaming/hifigan/hifigan_discriminators.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import s3prl.hub\n",
    "import librosa\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "from importlib import reload\n",
    "import wav2avatar.streaming.hifigan.hifigan_generator as hifigan\n",
    "import wav2avatar.streaming.hifigan.hifigan_discriminators as hifigan_discriminators\n",
    "from wav2avatar.streaming.hifigan.wav_ema_dataset import WavEMADataset\n",
    "import wav2avatar.streaming.hifigan.collate\n",
    "reload(hifigan)\n",
    "reload(wav2avatar.streaming.hifigan.collate)\n",
    "reload(wav2avatar.streaming.hifigan.wav_ema_dataset)\n",
    "reload(hifigan_discriminators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prabhune/miniconda3/envs/w2a/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "device = 0\n",
    "wlm = getattr(s3prl.hub, \"wavlm_large\")()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio loaded: torch.Size([1, 280918])\n"
     ]
    }
   ],
   "source": [
    "wav = \"../../inversion/wav/mlk.wav\"\n",
    "sr = 16000\n",
    "audio, a_sr = torchaudio.load(wav)\n",
    "audio = audio.to(0)\n",
    "if audio.shape[0] > 1:\n",
    "    audio = audio[0]\n",
    "if a_sr != sr:\n",
    "    audio = torchaudio.functional.resample(\n",
    "        audio, orig_freq=a_sr, new_freq=sr\n",
    "    )\n",
    "audio = audio.unsqueeze(0)\n",
    "print(f\"Audio loaded: {audio.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlm_cnn = wlm.model.feature_extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 877])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlm_cnn(audio).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = hifigan.HiFiGANGenerator(in_channels=512, out_channels=12, ar_input=600).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 877])\n",
      "torch.Size([34, 512, 50])\n"
     ]
    }
   ],
   "source": [
    "x = wlm_cnn(audio).to(device)\n",
    "print(x.shape)\n",
    "\n",
    "collates = [x[:, :, i:i+50] for i in range(0, x.shape[2] // 50 * 50, 25)]\n",
    "\n",
    "x_collated = torch.concatenate(collates)\n",
    "print(x_collated.shape)\n",
    "#xs = [x[:, :, 0:5]] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 12, 50])\n"
     ]
    }
   ],
   "source": [
    "ar = torch.zeros((x_collated.shape[0], 12, 50)).to(device)\n",
    "#ars = [ar[:, 0:5]] * 5\n",
    "\n",
    "print(ar.shape)\n",
    "#print(len(ars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 512, 50])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputconv: torch.Size([12, 256, 50])\n",
      "torch.Size([12, 12, 50])\n"
     ]
    }
   ],
   "source": [
    "audio_feats = audio_feats.to(device)\n",
    "ema = ema.to(device)\n",
    "pred = gan(audio_feats, ema)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.557375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.shape[1] / 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prabhune/miniconda3/envs/w2a/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "msd_mpd = hifigan_discriminators.HiFiGANMultiScaleMultiPeriodDiscriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msd_mpd(pred)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_audio(audio_list, start_idxs):\n",
    "    \"\"\"Pad a batch of audio\"\"\"\n",
    "    # Prepare audio for training or validation\n",
    "    # Crop audio\n",
    "    return torch.concatenate([\n",
    "        x[:, :, start_idx:start_idx + 256]\n",
    "        for x, start_idx in zip(audio_list, start_idxs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_collate = prepare_audio([x, x], [0, 511])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 877])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from directories...\n"
     ]
    }
   ],
   "source": [
    "wav_ema_dataset = WavEMADataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data/prabhune/VCTK/p225/mngu0_wlm_est/p225_001_mic1.npy'),\n",
       " PosixPath('/data/prabhune/VCTK/p225/mngu0_wlm_est/p225_001_mic2.npy'),\n",
       " PosixPath('/data/prabhune/VCTK/p225/mngu0_wlm_est/p225_002_mic1.npy'),\n",
       " PosixPath('/data/prabhune/VCTK/p225/mngu0_wlm_est/p225_002_mic2.npy'),\n",
       " PosixPath('/data/prabhune/VCTK/p225/mngu0_wlm_est/p225_003_mic1.npy')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_ema_dataset.ema_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data/all_data/VCTK/p225/wav_16/p225_001_mic1.wav'),\n",
       " PosixPath('/data/all_data/VCTK/p225/wav_16/p225_001_mic2.wav'),\n",
       " PosixPath('/data/all_data/VCTK/p225/wav_16/p225_002_mic1.wav'),\n",
       " PosixPath('/data/all_data/VCTK/p225/wav_16/p225_002_mic2.wav'),\n",
       " PosixPath('/data/all_data/VCTK/p225/wav_16/p225_003_mic1.wav')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_ema_dataset.wav_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=wav_ema_dataset, batch_size=5, shuffle=True, collate_fn=wav2avatar.streaming.hifigan.collate.car_collate)\n",
    "\n",
    "audio_feats, ema, ema_ar = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512, 50])\n",
      "torch.Size([16, 12, 50])\n"
     ]
    }
   ],
   "source": [
    "print(audio_feats.shape)\n",
    "print(ema_ar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 817])\n",
      "torch.Size([1, 12, 817])\n"
     ]
    }
   ],
   "source": [
    "print(torch.concatenate(audio_feats, dim=2).shape)\n",
    "print(torch.concatenate(ema, dim=2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 12)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"/data/prabhune/VCTK/p225/mngu0_wlm_est/p225_030_mic1.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 66817])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio, sr = torchaudio.load(\"/data/all_data/VCTK/p225/wav_16/p225_030_mic1.wav\")\n",
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1760625"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "66817/16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.16"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "208/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
